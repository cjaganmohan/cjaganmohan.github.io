---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---



My research interest is at the intersection of software engineering and artificial intelligence (AI) and deals with the problem of establishing standards, measurements, and safeguards for AI-enabled software systems (AI systems). My research aims to address quality challenges in AI systems using software engineering principles and methodologies to guarantee trustworthy and responsible AI systems. I am particularly interested in advancing the state of the art in evaluating AI systems and developing methods, approaches, and tools to test and ensure that AI systems are safe, secure and reliable.


<!--

My research is at the intersection of Software Engineering (SE) and Artificial Intelligence (AI), focusing on addressing the software engineering challenges in the AI system development lifecycle. My current focus is on developing approaches to test and evaluate ML-enabled systems across its lifecycle.
# Recent Projects 

## Fairness Testing
Machine Learning (ML) models derive their decision logic from a dataset. Bias from the dataset could be introduced to the model across the ML model development lifecycle. This project presents a ***model-agnostic approach*** to perform ***fairness testing*** of ML models. We presented a combinatorial approach to test pre-trained ML models for individual fairness violations. [(preprint)](https://cjaganmohan.github.io/files/A_Combinatorial_Approach_to_Fairness_Testing_of-Machine_Learning_Models.pdf)

## Explainable AI (XAI)

### Adopting a software fault localization approach for XAI
To develop an explainable AI (XAI) tool that shall produce explanations for decisions made by Deep Neural Network (DNN) models. The explanation can help engineers determine the cause of incorrect decisions of an DNN model (i.e., debugging an DNN model). Conceptually, **deriving a local explanation** for a modelâ€™s decision (XAI) is **similar to software fault localization**, a well-studied problem in software engineering.  In this project, I proposed an approach that adopts an existing software fault localization technique and produce explanations for decisions made by DNN models. -- [(preprint)](https://cjaganmohan.github.io/files/XAI_Tool_pre_print_IWCT_2021.pdf), [(video)](https://www.youtube.com/watch?v=uGdJnsvC7m4) 

### Causality based approach for XAI
A causality-based approach to explain model's outcomes. The presented approach aims to provide two sets of explanations: Given a model and its outcomes, the causal-inference-based approach can provide explanations of how different parameters contribute to a model's decision. Furthermore, the explanations generated using our approach enable practitioners to understand and quantify the impact of each parameter on the model's outcome.


## Test Input Generation for Testing DNN models
Generating data to test AI systems, particularly for image-based AI systems such as autonomous driving systems, is a time-consuming and expensive process. In this project we propose a combinatorial approach to generate test data (images) to test Deep Neural Network (DNN) models used in autonomous driving cars. Each test input represents a combination of image transformations, and can be used to produce a test image. We conducted an experimental evaluation of our approach on three DNN models that are used in the Udacity challenge. Results suggest that combinatorial testing can be effectively applied, and the proposed approach detects a significant number of inconsistent (or undesired) behaviors in pre-trained DNN models developed to predict the steering angle of a car.  -- [(preprint)](https://cjaganmohan.github.io/files/Testing_DNN_pre_print_IWCT_2021.pdf), [(video)](https://www.youtube.com/watch?v=978CwhOWG54)

## Test cost reduction
Many machine learning algorithms examine large amounts of data to discover insights from hidden patterns. Testing these algorithms can be expensive and time- consuming. There is a need to speed up the testing process, especially in an agile development process, where testing is frequently performed. One approach is to replace big datasets with smaller datasets produced by random sampling. In this project, we report a set of experiments that are designed to evaluate the effectiveness of using reduced datasets produced by random sampling for testing machine learning algorithms. Results suggest that reduced datasets can be used to accelerate the testing phase of ML applications while largely preserving the fault detection effectiveness of the original datasets. -- [(preprint)](https://cjaganmohan.github.io/files/Effectiveness_of_dataset_reduction_pre_print_AITest2020.pdf), [(video)](https://www.youtube.com/watch?v=j_4Nz04hmbM)

-->




